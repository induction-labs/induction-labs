{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436000f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.data.video_action import fetch_data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
=======
   "execution_count": 2,
   "id": "9abc0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a694c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Omni-3B\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
>>>>>>> Stashed changes
   "id": "f4281e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: images.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(non_video_input_ids)=4, len(video_input_ids)=4080, num_video_tokens=4080, seq_length=8192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ActionDataSample(qwen_inputs=QwenInputs(input_ids=tensor([151644,    872,    198,  ...,      0,      0,      0]), attention_mask=tensor([1, 1, 1,  ..., 0, 0, 0]), pixel_values_videos=tensor([[1.9303, 1.9303, 1.9303,  ..., 2.1459, 2.1459, 2.1459],\n",
       "        [1.9303, 1.9303, 1.9303,  ..., 2.1459, 2.1459, 2.1459],\n",
       "        [1.9303, 1.9303, 1.9303,  ..., 2.1459, 2.1459, 2.1459],\n",
       "        ...,\n",
       "        [1.9303, 1.9303, 1.9303,  ..., 2.1459, 2.1459, 2.1459],\n",
       "        [1.9303, 1.9303, 1.9303,  ..., 2.1459, 2.1459, 2.1459],\n",
       "        [1.9303, 1.9303, 1.9303,  ..., 2.1459, 2.1459, 2.1459]]), video_grid_thw=tensor([[ 8, 34, 60]]), video_second_per_grid=tensor([1.])), cursor_path=tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]]), action_tokens=tensor([False, False, False,  ..., False, False, False]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await fetch_data(\n",
    "  num_actions=8,\n",
    "  path=\"gs://induction-labs/jonathan/synth/cursor_follow_v1/sample_3.zarr\",\n",
    "  seq_length=8192,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d01b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n",
       "        151656, 151656, 151656, 151656, 151656, 151656,     -1,      0,      0,\n",
       "             0,      0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.qwen_inputs.input_ids[-20:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
