apiVersion: v1
kind: Pod
metadata:
  name: nbody-gpu-benchmark
spec:
  restartPolicy: OnFailure
  runtimeClassName: nvidia
  containers:
    - name: cuda-container
      image: pytorch/pytorch:2.7.0-cuda12.8-cudnn9-runtime
      # image: docker.io/nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04
      # args: ["nbody", "-gpu", "-benchmark"]
      args: ["sleep", "inf"]
      resources:
        limits:
          nvidia.com/gpu: 1
      env:
        # - name: NVIDIA_VISIBLE_DEVICES
        #   value: all
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: all
  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
