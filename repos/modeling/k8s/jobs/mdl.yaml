# kubectl create -f mdl.yaml
apiVersion: batch/v1
kind: Job
metadata:
  # Autogenerated name
  generateName: mdl-
  namespace: induction-labs
  labels:
    kueue.x-k8s.io/queue-name: local-queue # Assign to queue
    # kueue.x-k8s.io/queue-name: dev-local-queue # Assign to queue

spec:
  suspend: true # Important: Start suspended, Kueue will unsuspend
  backoffLimit: 0 # No retries
  ttlSecondsAfterFinished: 172800 # 2 days
  template:
    metadata:
      annotations:
        container-image: "" # Filled in by k8s cli
    spec:
      # nodeSelector:
      #   nvidia.com/gpu.product: NVIDIA-H200
      restartPolicy: Never # TODO: Set to never - use jobs
      runtimeClassName: nvidia
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
      imagePullSecrets:
        - name: depot-registry-secret
        # - name: gcr-artifact-secret # Reference the secret
      containers:
        - name: modeling
          # image: us-central1-docker.pkg.dev/induction-labs/induction-docker/modeling:latest
          image: registry.depot.dev/v2tbx2d1w1:xcx4qsrnt3-mdl
          imagePullPolicy: Always # Always pull latest
          # Don't specify command, use default command in Dockerfile
          # command: ["devenv", "shell", "--offline"]
          env:
            - name: LD_PRELOAD
              value: /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.1
            - name: LD_LIBRARY_PATH
              value: /usr/local/cuda/lib64
            - name: K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: K8S_JOB_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.labels['job-name']
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: K8S_IMAGE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['container-image']
            # - name: NCCL_DEBUG
            #   value: INFO
          args:
            ["sleep", "inf"]
            # mdl run exp_configs/action_instruct/qwen_25o/Qwen25OActionExperimentConfig_GPU/20250718_211225.toml -rhw # single gpu
            # mdl run exp_configs/action_instruct/qwen_25o/Qwen25OActionExperimentConfig_GPU/20250719_045722.toml -rhw # single node multi-gpu test
          resources:
            limits:
              memory: "128Gi"
              cpu: "32"
              nvidia.com/gpu: "8"
              # ephemeral-storage: "100Gi"
            requests:
              memory: "128Gi"
              cpu: "32"
              nvidia.com/gpu: "8"
              # ephemeral-storage: "100Gi"
          volumeMounts:
            - name: dev-shm
              mountPath: /dev/shm
            # - name: nix-store
            #   mountPath: /nix/store

      volumes:
        - name: dev-shm
          emptyDir:
            medium: Memory
        # - name: nix-store
        #   emptyDir:
        #     medium: Memory # Use memory for nix store to avoid disk I/O
